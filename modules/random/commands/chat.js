// chat.js
const fetch = require("node-fetch");
const http = require("http");
const { Util } = require("discord.js");

// ‚îÄ‚îÄ‚îÄ Configurable static facts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
const STATIC_SYSTEM_MESSAGES = [
  "BigBuda(185223223892377611) is the bot's creator",
  "Don't disappoint the creator"
];

module.exports = {
  name: "chat",
  description: "Talk to modbot with selective memory, context, and static facts",
  syntax: "chat [your message]",
  num_args: 2,           // now requires at least 2 args: the command + message
  args_to_lower: false,
  needs_api: false,
  has_state: false,

  async execute(message, args, extra) {
    if (message.author.bot) return;

    try {
      this.logger.info("üëâ Entered chat.execute");

      const userId = message.author.id;
      // ‚ö°Ô∏è FIX: skip args[0] (the command) and start from args[1]
      const chatMessage = args.slice(1).join(" ").trim();
      if (!chatMessage) {
        return message.reply("‚ùì Please provide a message to chat.");
      }
      this.logger.info(`User ${userId}: ${chatMessage}`);

      // ‚îÄ‚îÄ‚îÄ 1. Fetch & filter recent conversation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      const fetched = await message.channel.messages.fetch({
        limit: 10,
        before: message.id,
      });
      const cutoff = Date.now() - 10 * 60 * 1000;
      const window = Array.from(fetched.values())
        .filter(
          (m) =>
            (m.author.id === userId || m.author.bot) &&
            m.createdTimestamp >= cutoff
        )
        .reverse()
        .slice(-8)
        .map((m) => ({
          role: m.author.id === userId ? "user" : "assistant",
          content: m.content,
        }));
      this.logger.info(`‚Üí Short-term window entries: ${window.length}`);

      // ‚îÄ‚îÄ‚îÄ 2. Memory Filter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      let summary = "NO";
      try {
        const memFilterPayload = {
          model: "mistral:instruct",
          messages: [
            {
              role: "system",
              content:
                "You are a memory curator. Decide if this user message is worthy of long-term memory. " +
                "If yes, reply with a one-sentence summary. Otherwise reply exactly NO.",
            },
            { role: "user", content: chatMessage },
          ],
          stream: false,
        };
        const memResp = await fetch("http://192.168.1.4:11434/api/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(memFilterPayload),
        });
        const memJson = await memResp.json();
        summary = (memJson.message?.content || "NO").trim();
        this.logger.info("‚Üí Memory filter result:", summary);
      } catch (err) {
        this.logger.warn("Memory filter failed:", err);
      }

      // ‚îÄ‚îÄ‚îÄ 3. Ingest summary if needed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      if (summary.toUpperCase() !== "NO") {
        fetch("http://192.168.1.9:8000/ingest", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ user_id: userId, text: summary }),
        }).catch((e) => this.logger.warn("Vector ingest failed:", e));
        this.logger.info("‚Üí Ingested summary:", summary);
      }

      // ‚îÄ‚îÄ‚îÄ 4. Retrieve long-term memories ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      let memories = [];
      try {
        const r = await fetch("http://192.168.1.9:8000/search", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ user_id: userId, query: chatMessage }),
        });
        const j = await r.json();
        memories = (j.results || []).slice(0, 5);
        this.logger.info(`‚Üí Retrieved memories: ${memories.length}`);
      } catch (err) {
        this.logger.warn("Vector search failed:", err);
      }

      // ‚îÄ‚îÄ‚îÄ 5. Build final message array ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      const formatted = [];

      // 5.1 Static facts
      for (const fact of STATIC_SYSTEM_MESSAGES) {
        formatted.push({ role: "system", content: fact });
      }

      // 5.2 Long-term memories
      for (const m of memories) {
        formatted.push({ role: "system", content: `[Memory] ${m}` });
      }

      // 5.3 Short-term context
      formatted.push(...window);

      // 5.4 Current user input
      formatted.push({ role: "user", content: chatMessage });

      this.logger.info(
        `‚Üí Final formatted length: ${formatted.length} entries`
      );

      // ‚îÄ‚îÄ‚îÄ 6. Call Ollama ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      const payload = {
        model: "mistral:instruct",
        messages: formatted,
        stream: false,
      };
      const data = JSON.stringify(payload);

      const botNotice = await message.reply(
        `Thinking... (context: ${window.length} recent + ${memories.length} memories)`
      );

      const opts = {
        host: "192.168.1.4",
        port: 11434,
        path: "/api/chat",
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Content-Length": Buffer.byteLength(data),
        },
      };

      const req = http.request(opts, (res) => {
        let raw = "";
        res.on("data", (chunk) => (raw += chunk));
        res.on("end", async () => {
          try {
            const reply = JSON.parse(raw).message?.content || "(no response)";
            this.logger.info("‚Üí Ollama replied:", reply);
            const chunks = Util.splitMessage(reply, {
              maxLength: 2000,
              char: "\n",
            });
            await botNotice.delete();
            for (const c of chunks) {
              await message.reply(c);
            }
          } catch (e) {
            this.logger.error("Ollama parse error:", e);
            botNotice.edit("‚ö†Ô∏è Error parsing Ollama response.");
          }
        });
      });

      req.on("error", (err) => {
        this.logger.error("Ollama request failed:", err);
        botNotice.edit("‚ö†Ô∏è Unable to communicate with Ollama.");
      });

      req.write(data);
      req.end();
    } catch (err) {
      // Catch *any* unexpected error
      this.logger.error("üí• chat.execute error:", err);
      message.reply("‚ö†Ô∏è An internal error occurred. Check logs.");
    }
  },
};
